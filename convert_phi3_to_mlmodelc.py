import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig
import coremltools as ct
import numpy as np

MODEL_NAME = "microsoft/Phi-3-mini-4k-instruct"
OUTPUT_MODEL_NAME = "Phi3Mini.mlmodelc"

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)

# 2. –§–∏–∫—Å–∏–º rope_scaling (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!)
config = AutoConfig.from_pretrained(MODEL_NAME, trust_remote_code=True)
if hasattr(config, 'rope_scaling'):
    config.rope_scaling = None

# 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤ fp32 (–≤–∞–∂–Ω–æ!)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    config=config,
    torch_dtype=torch.float32,  # ‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º float32, –∞ –Ω–µ "auto"
    trust_remote_code=True,
    device_map=None,
    low_cpu_mem_usage=True,
)

# 4. –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ eval-—Ä–µ–∂–∏–º –∏ –æ—Ç–∫–ª—é—á–∞–µ–º dropout
model.eval()
model = model.to("cpu")

# 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥ (–≤–∞–∂–Ω–æ: –¥–ª–∏–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π!)
prompt = "Hello, how are you?"
inputs = tokenizer(prompt, return_tensors="pt", padding="max_length", max_length=128, truncation=True)
input_ids = inputs["input_ids"]  # Shape: [1, 128]
attention_mask = inputs["attention_mask"]  # Shape: [1, 128]

# 6. ‚úÖ –°–û–ó–î–ê–Å–ú TORCHSCRIPT –ß–ï–†–ï–ó trace() ‚Äî –ö–õ–Æ–ß–ï–í–û–ô –®–ê–ì!
print("üîÑ –°–æ–∑–¥–∞—ë–º TorchScript —á–µ—Ä–µ–∑ tracing...")

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É –≤—Ö–æ–¥–∞ –¥–ª—è tracing
class Phi3Wrapper(torch.nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model

    def forward(self, input_ids, attention_mask):
        return self.model(input_ids=input_ids, attention_mask=attention_mask).logits

wrapper = Phi3Wrapper(model)

# –í—ã–ø–æ–ª–Ω—è–µ–º tracing
traced_model = torch.jit.trace(
    wrapper,
    (input_ids, attention_mask),
    check_trace=False,  # ‚ö†Ô∏è –ò–Ω–æ–≥–¥–∞ trace –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç ‚Äî –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
    strict=False
)

print("‚úÖ TorchScript —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!")

# 7. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Core ML ‚Äî —Ç–µ–ø–µ—Ä—å source –Ω–µ –Ω—É–∂–µ–Ω, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ TorchScript
print("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º TorchScript –≤ Core ML...")

mlmodel = ct.convert(
    traced_model,
    inputs=[
        ct.TensorType(name="input_ids", shape=input_ids.shape, dtype=np.int32),
        ct.TensorType(name="attention_mask", shape=attention_mask.shape, dtype=np.int32),
    ],
    convert_to="mlprogram",
    compute_units=ct.ComputeUnit.ALL,
    skip_model_load=True,
)

# 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º
mlmodel.save(OUTPUT_MODEL_NAME)
print(f"üéâ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {OUTPUT_MODEL_NAME}")

