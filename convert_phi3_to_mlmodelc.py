# convert_phi3_to_mlmodelc.py

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import coremltools as ct

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
MODEL_NAME = "microsoft/Phi-3-mini-4k-instruct"
OUTPUT_MODEL_NAME = "Phi3Mini.mlmodelc"

print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –º–æ–¥–µ–ª—å...")

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥, —á—Ç–æ–±—ã –∏—Å–ø—Ä–∞–≤–∏—Ç—å rope_scaling
from transformers import AutoConfig
config = AutoConfig.from_pretrained(MODEL_NAME, trust_remote_code=True)

# üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—ë–º rope_scaling, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –∏–ª–∏ –æ–Ω –ø—É—Å—Ç
if not config.rope_scaling:
    config.rope_scaling = {"type": "linear"}  # ‚Üê –§–ò–ö–°: –¥–æ–±–∞–≤–ª—è–µ–º —Ç–∏–ø
elif isinstance(config.rope_scaling, dict) and "type" not in config.rope_scaling:
    config.rope_scaling["type"] = "linear"   # ‚Üê –§–ò–ö–°: –µ—Å–ª–∏ –µ—Å—Ç—å, –Ω–æ –Ω–µ—Ç "type"

# –¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º –∫–æ–Ω—Ñ–∏–≥–æ–º
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    config=config,  # ‚Üê –ò–°–ü–û–õ–¨–ó–£–ï–ú –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ö–û–ù–§–ò–ì
    torch_dtype="auto",
    trust_remote_code=True,
    device_map=None,         # ‚Üê –í–ê–ñ–ù–û: –æ—Ç–∫–ª—é—á–∞–µ–º device_map
    low_cpu_mem_usage=True,  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è M1
)

# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–∞
prompt = "Hello, how are you?"
inputs = tokenizer(prompt, return_tensors="pt")
input_ids = inputs["input_ids"]

print(f"‚úÖ –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä: {input_ids.shape}")

# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ Core ML
print("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ Core ML (—ç—Ç–æ –∑–∞–π–º–µ—Ç 5‚Äì10 –º–∏–Ω—É—Ç)...")
mlmodel = ct.convert(
    model,
    inputs=[
        ct.TensorType(
            name="input_ids",
            shape=input_ids.shape,
            dtype=input_ids.dtype
        )
    ],
    convert_to="mlprogram",
    compute_units=ct.ComputeUnit.ALL,
    skip_model_load=True
)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∫–∞–∫ {OUTPUT_MODEL_NAME}...")
mlmodel.save(OUTPUT_MODEL_NAME)

print(f"üéâ –ì–æ—Ç–æ–≤–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {OUTPUT_MODEL_NAME}")
